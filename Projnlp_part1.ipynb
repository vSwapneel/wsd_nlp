{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1Xz6iWZwaUR",
    "outputId": "3805bf78-e5d4-4bc5-b3e3-a494b567cb31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from fsspec[http]>=2021.11.1->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (0.24.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yrgE7McbtbQ_",
    "outputId": "fb148cd5-a679-4644-ef2e-0a86da28bbba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Suhas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S8z3lsqBJihF"
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "def get_synset(lemma, pos, model, tokenizer, known_synset_embeddings, collect_only=False, unique_synsets=None):\n",
    "    \"\"\"\n",
    "    Map a lemma and POS to its corresponding WordNet synset.\n",
    "    Use embedding-based similarity fallback if necessary.\n",
    "\n",
    "    Args:\n",
    "        lemma (str): Lemma of the word.\n",
    "        pos (str): Part of speech of the word.\n",
    "        model: Fine-tuned BERT model.\n",
    "        tokenizer: Tokenizer used with the model.\n",
    "        known_synset_embeddings: Precomputed embeddings for known synsets.\n",
    "        collect_only (bool): If True, only collect synsets without fallback.\n",
    "        unique_synsets (set): A set to collect unique synsets.\n",
    "\n",
    "    Returns:\n",
    "        str: Synset name or \"UNK\" if not found.\n",
    "    \"\"\"\n",
    "    pos_map = {\"NOUN\": wn.NOUN, \"VERB\": wn.VERB, \"ADJ\": wn.ADJ, \"ADV\": wn.ADV}\n",
    "    wn_pos = pos_map.get(pos)\n",
    "\n",
    "    # Attempt to retrieve synsets from WordNet\n",
    "    if wn_pos:\n",
    "        synsets = wn.synsets(lemma, pos=wn_pos)\n",
    "        if synsets:\n",
    "            synset = synsets[0].name()  # First synset\n",
    "            if collect_only and unique_synsets is not None:\n",
    "                unique_synsets.add(synset)  # Collect unique synsets\n",
    "            return synset\n",
    "\n",
    "    # Skip fallback during collection\n",
    "    if collect_only:\n",
    "        return \"UNK\"\n",
    "\n",
    "    # Fallback: Find closest synset embedding for OOV words\n",
    "    try:\n",
    "        word_embedding = model.get_input_embeddings()(\n",
    "            torch.tensor([tokenizer.convert_tokens_to_ids(lemma)])\n",
    "        ).detach().numpy()\n",
    "        closest_synset = get_closest_synset(word_embedding, known_synset_embeddings)\n",
    "        return closest_synset\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding closest synset for OOV word '{lemma}': {e}\")\n",
    "        return \"UNK\"\n",
    "\n",
    "def get_closest_synset(embedding, known_synset_embeddings):\n",
    "    \"\"\"\n",
    "    Find the closest synset based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        embedding (np.ndarray): Embedding for the OOV word.\n",
    "        known_synset_embeddings (dict): Precomputed embeddings for known synsets.\n",
    "\n",
    "    Returns:\n",
    "        str: Synset with the highest similarity.\n",
    "    \"\"\"\n",
    "    similarities = {\n",
    "        synset: cosine_similarity(embedding.reshape(1, -1), known_embedding.reshape(1, -1))[0][0]\n",
    "        for synset, known_embedding in known_synset_embeddings.items()\n",
    "    }\n",
    "    return max(similarities, key=similarities.get)\n",
    "\n",
    "def parse_xml_dataset(xml_path, model=None, tokenizer=None, known_synset_embeddings=None, collect_only=False):\n",
    "    \"\"\"\n",
    "    Parse XML dataset, collect unique synsets, and preprocess sentences in one pass.\n",
    "\n",
    "    Args:\n",
    "        xml_path (str): Path to the XML file.\n",
    "        model: Fine-tuned BERT model (optional).\n",
    "        tokenizer: Tokenizer used with the model (optional).\n",
    "        known_synset_embeddings: Precomputed embeddings for known synsets (optional).\n",
    "        collect_only (bool): If True, only collect unique synsets without preprocessing.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing texts and labels.\n",
    "        set: Unique synsets collected from the dataset.\n",
    "    \"\"\"\n",
    "    texts, labels = [], []\n",
    "    unique_synsets = set()\n",
    "\n",
    "    for event, elem in ET.iterparse(xml_path, events=(\"start\", \"end\")):\n",
    "        if event == \"end\" and elem.tag == \"sentence\":\n",
    "            sentence_text = []\n",
    "            sentence_labels = []\n",
    "\n",
    "            for child in elem:\n",
    "                if child.tag == \"wf\":\n",
    "                    sentence_text.append(child.text)\n",
    "                elif child.tag == \"instance\":\n",
    "                    sentence_text.append(child.text)\n",
    "                    synset = get_synset(\n",
    "                        child.attrib.get(\"lemma\", \"\"),\n",
    "                        child.attrib.get(\"pos\", \"\"),\n",
    "                        model,\n",
    "                        tokenizer,\n",
    "                        known_synset_embeddings,\n",
    "                        collect_only=collect_only,\n",
    "                        unique_synsets=unique_synsets\n",
    "                    )\n",
    "                    sentence_labels.append({\n",
    "                        \"id\": child.attrib.get(\"id\", \"\"),\n",
    "                        \"lemma\": child.attrib.get(\"lemma\", \"\"),\n",
    "                        \"pos\": child.attrib.get(\"pos\", \"\"),\n",
    "                        \"synset\": synset\n",
    "                    })\n",
    "\n",
    "            texts.append(\" \".join(sentence_text))\n",
    "            labels.append(sentence_labels)\n",
    "            elem.clear()  # Free memory\n",
    "\n",
    "    return pd.DataFrame({\"text\": texts, \"labels\": labels}), unique_synsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cCX7LHhjs-ih"
   },
   "outputs": [],
   "source": [
    "xml_path = \"./WSD_Training_Corpora/SemCor/semcor.data.xml\"\n",
    "\n",
    "# Step 1: Collect synsets and preprocess dataset\n",
    "parsed_data, unique_synsets = parse_xml_dataset(xml_path, collect_only=True)\n",
    "\n",
    "# Step 2: Map synsets to IDs\n",
    "synset_to_id = {synset: idx for idx, synset in enumerate(unique_synsets)}\n",
    "id_to_synset = {idx: synset for synset, idx in synset_to_id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336,
     "referenced_widgets": [
      "c05bcb16a4e74722a18f68407b9f9e79",
      "3528559911c6447e8145c4f5da80f15a",
      "3ad62049d0514655912c801a3a6c33af",
      "a9fe243d8cfe48a7900c9b8784f3f951",
      "e67f94e0b1fe4cdf9be788540ba5b921",
      "0bc8a0e16cd64bcea716208adf605475",
      "7072ae437f054c679f1f638ddc8a5fcf",
      "06a444a0f4994ee3b678e6d38e74d9f2",
      "f7c4addd8e2146b4b45e035c693cc558",
      "ed57552d689b405b9dc63eb2ebf89628",
      "bfe550841e0340efa726623d13d56d42",
      "77b2a19e25a24d90ad73a865505d68a8",
      "59d0d5d8e2e24b32a51719a23b450c79",
      "8352f29cbe2a42069fd1c2491e54355c",
      "837cfc32f9a34ada8c810fe3ba9b889b",
      "687c1412605b456e81b657a66de40d68",
      "a88d0525d04e418498a95932e6cb9bc7",
      "6609b1ff7b054fadbb1a2f7039cab62a",
      "866d39cfef2243cf8921df0b6c056ed6",
      "84c0c32bf99045fd9a23bfcb55189242",
      "dc246ef0646b4c9eaa44b627eb35557c",
      "dc22f864fc8f4ec3a63d573ee2d785c1",
      "29c0a18d551d437ba46ad56f121ccf0a",
      "6b68842c581f4027a61756cd1712ccc5",
      "c72903775d144d0e8531bc5206346fe5",
      "61772e9e02874be48d30d6e2706c203a",
      "2bb89fe85cdc420ba1622b5fcf297ddc",
      "961c3571d38e4c13a76d6246470f9497",
      "4a2829465b004a1496976ce2cdf30c26",
      "a0ff159a3dc548c5881db5b772f0c6e2",
      "258c4abcb7614310b46626b3ad75f26c",
      "0a995c7a035d441ea370cebe72eaf8f0",
      "e53607d484084e1ca67d5b2197900e75",
      "9bc755cbdd6745d3a872a07229f913fb",
      "cc5116f44b6249d2baa9c72fa1850f0c",
      "13c55af7d4aa41749834e95f24c847d6",
      "833cf2599d574c79815f1abd963d2b4a",
      "9b39f39e51cc43a4a85c09f02bef2baa",
      "1fb34004a1304c3f99053b68e0aa978e",
      "fdfac33240d04a9b8ae1f279ef3f9e1e",
      "2726deb1ca1d4676986b1c69b3f52d74",
      "ed87a50374dc4cf3906ba1bdffcab1cc",
      "867c79cb14b24ad4a9001f480c03ceae",
      "a519dd3bafa941ea8c096dd957361baf",
      "419a7943ed37457c970370a10a84d916",
      "113a61d6c9d24dd5bb1ad7c68b60d340",
      "f5bc40fe5dd8412cab460d1feac02397",
      "52b8ccf4212348f2a3cd7b4f049b5d6e",
      "9831527b26bd4cd488155a98aa4ec661",
      "09d7738d0e7449ee88c6d14a71ba047f",
      "21c5b56432c145749e7f0f5b3664aee6",
      "dbd76c78abf64bd7be9161ed777972bb",
      "46929edf6ad54411a531ee7c60973bc0",
      "922e5c71c5914e8eafefbd23c5c0dfe1",
      "2dcf4b880d984be8aa26095f45efb796"
     ]
    },
    "id": "z-SO6iVwtOim",
    "outputId": "9377a7df-7e4a-49b9-e935-f44193014c68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, BertTokenizerFast\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(synset_to_id))\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Precompute embeddings for known synsets\n",
    "known_synset_embeddings = {\n",
    "    synset: model.get_input_embeddings()(\n",
    "        torch.tensor([tokenizer.convert_tokens_to_ids(synset)])\n",
    "    ).detach().numpy()\n",
    "    for synset in synset_to_id.keys()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yXdCSMkntRcU"
   },
   "outputs": [],
   "source": [
    "# Parse dataset with embedding-based fallback\n",
    "final_data, _ = parse_xml_dataset(xml_path, model, tokenizer, known_synset_embeddings, collect_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "k_AExkwuuwGp"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(data_df, tokenizer, synset_to_id, max_length=128):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by tokenizing the text and aligning labels.\n",
    "\n",
    "    Args:\n",
    "        data_df (pd.DataFrame): Parsed dataset with 'text' and 'labels'.\n",
    "        tokenizer: BERT tokenizer.\n",
    "        synset_to_id (dict): Mapping of synsets to numeric IDs.\n",
    "        max_length (int): Maximum sequence length for tokenized inputs.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: Preprocessed data with tokenized inputs and aligned labels.\n",
    "    \"\"\"\n",
    "    tokenized_data = []\n",
    "\n",
    "    for _, row in data_df.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        labels = row[\"labels\"]\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokenized_inputs = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=0)\n",
    "\n",
    "        # Map synsets to numeric IDs\n",
    "        label_dict = {\n",
    "            int(label[\"id\"].split(\".\")[-1].lstrip(\"t\")): synset_to_id.get(label[\"synset\"], -100)\n",
    "            for label in labels\n",
    "        }\n",
    "\n",
    "        # Align labels with tokens\n",
    "        token_labels = []\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:  # Special tokens\n",
    "                token_labels.append(-100)\n",
    "            elif word_id in label_dict:\n",
    "                token_labels.append(label_dict[word_id])\n",
    "            else:\n",
    "                token_labels.append(-100)\n",
    "\n",
    "        tokenized_inputs[\"labels\"] = token_labels\n",
    "        tokenized_data.append({\n",
    "            \"input_ids\": tokenized_inputs[\"input_ids\"].squeeze().tolist(),\n",
    "            \"attention_mask\": tokenized_inputs[\"attention_mask\"].squeeze().tolist(),\n",
    "            \"labels\": token_labels\n",
    "        })\n",
    "\n",
    "    return tokenized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0tnd2XEGv5Xj"
   },
   "outputs": [],
   "source": [
    "def convert_to_hf_dataset(tokenized_data):\n",
    "    return Dataset.from_dict({\n",
    "        \"input_ids\": [data[\"input_ids\"] for data in tokenized_data],\n",
    "        \"attention_mask\": [data[\"attention_mask\"] for data in tokenized_data],\n",
    "        \"labels\": [data[\"labels\"] for data in tokenized_data],\n",
    "    })\n",
    "\n",
    "# Preprocess the parsed data\n",
    "tokenized_data = preprocess_dataset(final_data, tokenizer, synset_to_id)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "hf_dataset = convert_to_hf_dataset(tokenized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49BopCaExVeG",
    "outputId": "7007e7fe-806e-48f8-b9b6-c6a14c89e383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2129, 2146, 2038, 2009, 2042, 2144, 2017, 8182, 1996, 11100, 1997, 2115, 5770, 1998, 2326, 2565, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, 9799, 5964, 2381, 17965, 2440, 17885, 7227, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "print(hf_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q2WSd2K7xiKZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics: Precision, Recall, F1-Score, and Perplexity.\n",
    "\n",
    "    Args:\n",
    "        eval_pred: A tuple of (logits, labels) from the Trainer evaluation.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of computed metrics.\n",
    "    \"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Mask out padding and special tokens (-100)\n",
    "    true_labels = labels[labels != -100]\n",
    "    true_predictions = predictions[labels != -100]\n",
    "\n",
    "    # Calculate Precision, Recall, and F1-Score\n",
    "    precision = precision_score(true_labels, true_predictions, average=\"weighted\")\n",
    "    recall = recall_score(true_labels, true_predictions, average=\"weighted\")\n",
    "    f1 = f1_score(true_labels, true_predictions, average=\"weighted\")\n",
    "\n",
    "    # Calculate Perplexity\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    log_probs = np.log(np.max(probs, axis=-1) + 1e-9)  # Adding epsilon for numerical stability\n",
    "    perplexity = np.exp(-np.mean(log_probs[labels != -100]))\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"perplexity\": perplexity,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "V1jGTuyZZIDJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.44.1-py3-none-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bitsandbytes) (2.4.1+cu121)\n",
      "Requirement already satisfied: numpy in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bitsandbytes) (1.23.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->bitsandbytes) (3.15.4)\n",
      "Collecting typing-extensions>=4.8.0 (from torch->bitsandbytes)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->bitsandbytes) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from torch->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.44.1-py3-none-win_amd64.whl (121.5 MB)\n",
      "   ---------------------------------------- 0.0/121.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 7.3/121.5 MB 41.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 16.3/121.5 MB 40.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 24.1/121.5 MB 39.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 27.8/121.5 MB 33.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 34.3/121.5 MB 34.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 45.6/121.5 MB 35.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 54.5/121.5 MB 36.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 63.2/121.5 MB 36.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 71.6/121.5 MB 36.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 73.9/121.5 MB 35.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 79.7/121.5 MB 34.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 90.2/121.5 MB 35.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 94.1/121.5 MB 34.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 97.5/121.5 MB 32.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 97.5/121.5 MB 32.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  121.4/121.5 MB 35.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 121.5/121.5 MB 18.4 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, bitsandbytes\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed bitsandbytes-0.44.1 typing-extensions-4.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyppeteer 2.0.0 requires urllib3<2.0.0,>=1.25.8, but you have urllib3 2.2.3 which is incompatible.\n",
      "tensorflow-gpu 2.10.1 requires keras<2.11,>=2.10.0, but you have keras 2.13.1 which is incompatible.\n",
      "tensorflow-gpu 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorflow-gpu 2.10.1 requires tensorboard<2.11,>=2.10, but you have tensorboard 2.13.0 which is incompatible.\n",
      "tensorflow-gpu 2.10.1 requires tensorflow-estimator<2.11,>=2.10.0, but you have tensorflow-estimator 2.13.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "QWfumZrGyE0s",
    "outputId": "ab9c78d7-a47b-4871-8403-cafe7246fd2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhas\\AppData\\Local\\Temp\\ipykernel_8960\\3735275745.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "You are resuming training from a checkpoint trained with 4.46.3 of Transformers but your current version is 4.46.2. This is not recommended and could yield to errors or unwanted behaviors.\n",
      "c:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\trainer.py:3354: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3135' max='3135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3135/3135 : < :, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model found! Saving to ./best_model_20241127_222422\n",
      "Best model saved at: ./best_model_20241127_222422\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# Memory management utility\n",
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "# Set up GPU for training\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# Enable gradient checkpointing for memory optimization\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Move model to GPU for training\n",
    "model.to(torch.device(\"cuda\"))\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"no\",  # Disable automatic evaluation\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,  # Reduce if memory issues persist\n",
    "    per_device_eval_batch_size=1,  # Smaller batch size for evaluation\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",  # Save checkpoints at the end of each epoch\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    seed=42,\n",
    "    optim=\"adamw_bnb_8bit\",  # Optimizer for low-memory scenarios\n",
    "    gradient_accumulation_steps=4,  # Simulate larger batch sizes\n",
    "    fp16=True,  # Mixed precision training\n",
    "    load_best_model_at_end=False,  # Disable automatic loading\n",
    "    eval_accumulation_steps = 50,\n",
    ")\n",
    "\n",
    "# Split dataset into train and validation\n",
    "train_val_split = hf_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = train_val_split[\"train\"]\n",
    "val_dataset = train_val_split[\"test\"]\n",
    "\n",
    "# Move validation dataset to CPU\n",
    "val_dataset = val_dataset.map(lambda x: {k: torch.tensor(v).to(\"cpu\") for k, v in x.items()})\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=None,  # No automatic evaluation during training\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,  # Add custom metrics\n",
    ")\n",
    "\n",
    "# Custom training and evaluation loop\n",
    "# best_model_path = None\n",
    "best_metric = float(\"inf\")  # Assuming lower metric is better (e.g., loss)\n",
    "\n",
    "# for epoch in range(int(training_args.num_train_epochs)):\n",
    "#     print(f\"Starting Epoch {epoch + 1}/{training_args.num_train_epochs}\")\n",
    "    \n",
    "    # Train on GPU\n",
    "model.to(torch.device(\"cuda\"))\n",
    "clear_memory()\n",
    "# trainer.train()\n",
    "trainer.train(resume_from_checkpoint=\"./results/checkpoint-3135\")\n",
    "    \n",
    "    # Evaluate on CPU\n",
    "    # print(f\"Evaluating after Epoch {epoch + 1}\")\n",
    "    # model.to(torch.device(\"cpu\"))\n",
    "    # clear_memory()\n",
    "    # trainer.eval_dataset = val_dataset  # Update evaluation dataset\n",
    "    # metrics = trainer.evaluate()\n",
    "    # print(f\"Metrics for Epoch {epoch + 1}: {metrics}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    # current_metric = metrics[\"eval_loss\"]  # Replace with your preferred metric\n",
    "    # if current_metric < best_metric:\n",
    "    #     best_metric = current_metric\n",
    "\n",
    "current_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "best_model_path = f\"./best_model_{current_timestamp}\"\n",
    "print(f\"New best model found! Saving to {best_model_path}\")\n",
    "trainer.save_model(best_model_path)\n",
    "\n",
    "# Final best model path\n",
    "print(f\"Best model saved at: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "egqm7HbAx1nv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_dataset Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 3718\n",
      "})\n",
      "val_dataset_small Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,val_dataset)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_dataset_small\u001b[39m\u001b[38;5;124m\"\u001b[39m,val_dataset_small)\n\u001b[1;32m---> 15\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataset_small\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation Results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# eval_results = trainer.evaluate(val_dataset_small)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# print(f\"Evaluation Results: {eval_results}\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\trainer.py:3975\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3972\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3974\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3975\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3985\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\trainer.py:4221\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4219\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_accumulation_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39meval_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   4220\u001b[0m     all_losses\u001b[38;5;241m.\u001b[39mto_cpu_and_numpy()\n\u001b[1;32m-> 4221\u001b[0m     \u001b[43mall_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_cpu_and_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4222\u001b[0m     all_labels\u001b[38;5;241m.\u001b[39mto_cpu_and_numpy()\n\u001b[0;32m   4223\u001b[0m     all_inputs\u001b[38;5;241m.\u001b[39mto_cpu_and_numpy()\n",
      "File \u001b[1;32mc:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\trainer_pt_utils.py:337\u001b[0m, in \u001b[0;36mEvalLoopContainer.to_cpu_and_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marrays \u001b[38;5;241m=\u001b[39m new_arrays\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat:\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marrays \u001b[38;5;241m=\u001b[39m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marrays\u001b[38;5;241m.\u001b[39mextend(new_arrays)\n",
      "File \u001b[1;32mc:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\trainer_pt_utils.py:142\u001b[0m, in \u001b[0;36mnested_concat\u001b[1;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[0;32m    139\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported type for concatenation: got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\suhas\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\transformers\\trainer_pt_utils.py:112\u001b[0m, in \u001b[0;36mnumpy_pad_and_concatenate\u001b[1;34m(array1, array2, padding_index)\u001b[0m\n\u001b[0;32m    109\u001b[0m array2 \u001b[38;5;241m=\u001b[39m atleast_1d(array2)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(array1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m array1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m array2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[0;32m    115\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (array1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m array2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(array1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], array2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m array1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# eval_results = trainer.evaluate(val_dataset)\n",
    "# print(f\"Evaluation Results: {eval_results}\")\n",
    "\n",
    "clear_memory()\n",
    "\n",
    "training_args.per_device_eval_batch_size = 1\n",
    "training_args.eval_accumulation_steps = 10\n",
    "torch.cuda.empty_cache()  # Clear memory\n",
    "\n",
    "# Use only a subset of the validation dataset\n",
    "val_dataset_small = val_dataset.select(range(1000))  # First 1000 samples\n",
    "print(\"val_dataset\",val_dataset)\n",
    "print(\"val_dataset_small\",val_dataset_small)\n",
    "\n",
    "eval_results = trainer.evaluate(val_dataset_small)\n",
    "print(f\"Evaluation Results: {eval_results}\")\n",
    "\n",
    "\n",
    "# eval_results = trainer.evaluate(val_dataset_small)\n",
    "# print(f\"Evaluation Results: {eval_results}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFz1REZCzceR"
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "# Updated function for processing and mapping synsets with OOV handling\n",
    "def process_corpus_sections_incrementally_with_synsets(\n",
    "    xml_path, model, tokenizer, known_synset_embeddings, chunk_size=10000\n",
    "):\n",
    "    \"\"\"\n",
    "    Process large XML datasets incrementally with OOV handling for synset mapping.\n",
    "\n",
    "    Args:\n",
    "        xml_path (str): Path to the XML file.\n",
    "        model: Fine-tuned BERT model.\n",
    "        tokenizer: Tokenizer used with the model.\n",
    "        known_synset_embeddings (dict): Precomputed embeddings for known synsets.\n",
    "        chunk_size (int): Number of sentences per chunk.\n",
    "\n",
    "    Returns:\n",
    "        List[pd.DataFrame]: List of DataFrames, one per processed chunk.\n",
    "    \"\"\"\n",
    "    print(f\"Processing <corpus> sections from: {xml_path}\")\n",
    "\n",
    "    corpus_dfs = []  # Store data frames for each <corpus> section\n",
    "    texts, labels = [], []\n",
    "    inside_corpus = False\n",
    "    inside_text = False\n",
    "    corpus_count = 0\n",
    "    chunk_counter = 0\n",
    "\n",
    "    # Open the file and read it line-by-line\n",
    "    with open(xml_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            # Check for the start of a <corpus> section\n",
    "            if \"<corpus\" in line:\n",
    "                inside_corpus = True\n",
    "                texts, labels = [], []  # Reset lists for a new <corpus>\n",
    "                corpus_count += 1\n",
    "                print(f\"\\nProcessing <corpus> section {corpus_count}...\")\n",
    "\n",
    "            # Process each line only if we're inside a <corpus> section\n",
    "            if inside_corpus:\n",
    "                if \"<text\" in line:\n",
    "                    inside_text = True  # Start of a new <text> element\n",
    "                    text_buffer = [line]  # Reset the buffer\n",
    "\n",
    "                elif inside_text:\n",
    "                    text_buffer.append(line)  # Accumulate lines within <text>\n",
    "\n",
    "                    if \"</text>\" in line:  # End of <text> element\n",
    "                        inside_text = False\n",
    "                        # Parse the accumulated <text> element\n",
    "                        text_xml = \"\".join(text_buffer)\n",
    "                        text_elem = ET.fromstring(\"<root>\" + text_xml + \"</root>\")  # Wrap for valid XML\n",
    "\n",
    "                        # Process each sentence in the <text> element\n",
    "                        for sentence in text_elem.findall(\".//sentence\"):\n",
    "                            sentence_text = []\n",
    "                            sentence_labels = []\n",
    "\n",
    "                            # Extract words from <wf> and <instance> elements\n",
    "                            for word_elem in sentence:\n",
    "                                if word_elem.tag == \"wf\":\n",
    "                                    sentence_text.append(word_elem.text)\n",
    "                                elif word_elem.tag == \"instance\":\n",
    "                                    sentence_text.append(word_elem.text)\n",
    "                                    # Reuse get_synset with OOV handling\n",
    "                                    synset = get_synset(\n",
    "                                        word_elem.attrib.get(\"lemma\", \"\"),\n",
    "                                        word_elem.attrib.get(\"pos\", \"\"),\n",
    "                                        model,\n",
    "                                        tokenizer,\n",
    "                                        known_synset_embeddings\n",
    "                                    )\n",
    "                                    sentence_labels.append({\n",
    "                                        \"id\": word_elem.attrib.get(\"id\", \"\"),\n",
    "                                        \"lemma\": word_elem.attrib.get(\"lemma\", \"\"),\n",
    "                                        \"pos\": word_elem.attrib.get(\"pos\", \"\"),\n",
    "                                        \"synset\": synset\n",
    "                                    })\n",
    "\n",
    "                            # Append extracted sentence data to texts and labels\n",
    "                            if sentence_text:\n",
    "                                texts.append(\" \".join(sentence_text))\n",
    "                                labels.append(sentence_labels)\n",
    "\n",
    "                        # Check if we've reached the chunk size limit\n",
    "                        if len(texts) >= chunk_size:\n",
    "                            # Save the chunk to a DataFrame and clear memory\n",
    "                            corpus_df = pd.DataFrame({\"text\": texts, \"labels\": labels})\n",
    "                            corpus_dfs.append(corpus_df)\n",
    "                            print(f\"Processed {chunk_counter + 1} chunks of {chunk_size} records.\")\n",
    "                            chunk_counter += 1\n",
    "                            texts, labels = [], []  # Reset lists for the next chunk\n",
    "\n",
    "            # Check for the end of a <corpus> section\n",
    "            if \"</corpus>\" in line and inside_corpus:\n",
    "                inside_corpus = False\n",
    "                # Save any remaining data after the last chunk\n",
    "                if texts and labels:\n",
    "                    corpus_df = pd.DataFrame({\"text\": texts, \"labels\": labels})\n",
    "                    corpus_dfs.append(corpus_df)\n",
    "                    print(f\"Final chunk for <corpus> section {corpus_count}.\")\n",
    "                    texts, labels = [], []  # Correctly reset lists for the next corpus section\n",
    "\n",
    "    return corpus_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LN-qbUN2_b_r",
    "outputId": "0f470c3d-acdb-4dd8-c171-89368a76e16e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing <corpus> sections from: /content/data/semcor+omsti.data.xml\n",
      "\n",
      "Processing <corpus> section 1...\n",
      "Processed 1 chunks of 10000 records.\n",
      "Processed 2 chunks of 10000 records.\n",
      "Processed 3 chunks of 10000 records.\n",
      "Final chunk for <corpus> section 1.\n",
      "\n",
      "Processing <corpus> section 2...\n",
      "Test dataset preview:\n",
      "                                                text  \\\n",
      "0  How long has it been since you reviewed the ob...   \n",
      "1  Have you permitted it to become a giveaway pro...   \n",
      "2  What effort do you make to assess results of y...   \n",
      "3  Do you measure its relation to reduced absente...   \n",
      "4  Have you set specific objectives for your empl...   \n",
      "\n",
      "                                              labels  \n",
      "0  [{'id': 'd000.s000.t000', 'lemma': 'long', 'po...  \n",
      "1  [{'id': 'd000.s001.t000', 'lemma': 'permit', '...  \n",
      "2  [{'id': 'd000.s002.t000', 'lemma': 'effort', '...  \n",
      "3  [{'id': 'd000.s003.t000', 'lemma': 'measure', ...  \n",
      "4  [{'id': 'd000.s004.t000', 'lemma': 'set', 'pos...  \n"
     ]
    }
   ],
   "source": [
    "xml_path = \"/content/data/semcor+omsti.data.xml\"\n",
    "test_corpus_dfs = process_corpus_sections_incrementally_with_synsets(\n",
    "    xml_path, model, tokenizer, known_synset_embeddings, chunk_size=10000\n",
    ")\n",
    "\n",
    "# Combine all chunks into a single DataFrame (if memory permits)\n",
    "combined_test_df = pd.concat(test_corpus_dfs, ignore_index=True)\n",
    "print(\"Test dataset preview:\")\n",
    "print(combined_test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DuXPSmu_-vp"
   },
   "outputs": [],
   "source": [
    "tokenized_test_data = preprocess_dataset(combined_test_df, tokenizer, synset_to_id)\n",
    "hf_test_dataset = convert_to_hf_dataset(tokenized_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkFR-CcDCmvL",
    "outputId": "645a1a8d-ad6b-4bea-b942-cb5bed2a4548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Testing Dataset Sample:\n",
      "{'input_ids': [101, 2129, 2146, 2038, 2009, 2042, 2144, 2017, 8182, 1996, 11100, 1997, 2115, 5770, 1998, 2326, 2565, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, 17472, 6776, 1142, 15255, 18262, 18629, 2944, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessed Testing Dataset Sample:\")\n",
    "print(hf_test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3NfD08SCyct"
   },
   "outputs": [],
   "source": [
    "fine_tuned_model = BertForTokenClassification.from_pretrained(\"./results\")\n",
    "test_results = trainer.evaluate(test_hf_dataset)\n",
    "print(f\"Test Results: {test_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUtZF-wyELhA"
   },
   "source": [
    "INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5dWWbJxDCXl"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "\n",
    "def predict_synsets(sentence, model, tokenizer, id_to_synset, max_length=128):\n",
    "    \"\"\"\n",
    "    Predict WordNet synsets for each word in a given sentence using the fine-tuned model.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): Input sentence.\n",
    "        model: Fine-tuned BERT model.\n",
    "        tokenizer: Tokenizer used for the model.\n",
    "        id_to_synset (dict): Mapping from numeric label IDs to WordNet synsets.\n",
    "        max_length (int): Maximum length for tokenized sequences.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, str]]: List of (word, synset) tuples.\n",
    "    \"\"\"\n",
    "    # Tokenize the input sentence\n",
    "    inputs = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    # Get the word IDs for alignment\n",
    "    word_ids = inputs.word_ids(batch_index=0)\n",
    "\n",
    "    # Perform inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get predictions (logits -> argmax)\n",
    "    logits = outputs.logits\n",
    "    predictions = logits.argmax(dim=-1).squeeze().tolist()\n",
    "\n",
    "    # Map predictions to WordNet synsets\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    predicted_synsets = []\n",
    "    for word_id, pred in zip(word_ids, predictions):\n",
    "        if word_id is not None and pred in id_to_synset:\n",
    "            predicted_synsets.append(id_to_synset[pred])\n",
    "        else:\n",
    "            predicted_synsets.append(\"UNK\")  # Unknown or ignored token\n",
    "\n",
    "    # Align tokens with synsets\n",
    "    result = []\n",
    "    for token, synset in zip(tokens, predicted_synsets):\n",
    "        result.append((token, synset))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cuj0DL1pE_3t"
   },
   "outputs": [],
   "source": [
    "# Prompt user for input\n",
    "sentence = input(\"Enter a sentence: Everything happens for its own good.\")\n",
    "\n",
    "# Predict synsets\n",
    "predictions = predict_synsets(sentence, model, tokenizer, id_to_synset)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPredicted Synsets:\")\n",
    "for token, synset in predictions:\n",
    "    print(f\"{token}: {synset}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06a444a0f4994ee3b678e6d38e74d9f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09d7738d0e7449ee88c6d14a71ba047f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a995c7a035d441ea370cebe72eaf8f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bc8a0e16cd64bcea716208adf605475": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "113a61d6c9d24dd5bb1ad7c68b60d340": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09d7738d0e7449ee88c6d14a71ba047f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_21c5b56432c145749e7f0f5b3664aee6",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "13c55af7d4aa41749834e95f24c847d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2726deb1ca1d4676986b1c69b3f52d74",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed87a50374dc4cf3906ba1bdffcab1cc",
      "value": 231508
     }
    },
    "1fb34004a1304c3f99053b68e0aa978e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21c5b56432c145749e7f0f5b3664aee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "258c4abcb7614310b46626b3ad75f26c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2726deb1ca1d4676986b1c69b3f52d74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29c0a18d551d437ba46ad56f121ccf0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b68842c581f4027a61756cd1712ccc5",
       "IPY_MODEL_c72903775d144d0e8531bc5206346fe5",
       "IPY_MODEL_61772e9e02874be48d30d6e2706c203a"
      ],
      "layout": "IPY_MODEL_2bb89fe85cdc420ba1622b5fcf297ddc"
     }
    },
    "2bb89fe85cdc420ba1622b5fcf297ddc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dcf4b880d984be8aa26095f45efb796": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3528559911c6447e8145c4f5da80f15a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bc8a0e16cd64bcea716208adf605475",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7072ae437f054c679f1f638ddc8a5fcf",
      "value": "config.json:â€‡100%"
     }
    },
    "3ad62049d0514655912c801a3a6c33af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06a444a0f4994ee3b678e6d38e74d9f2",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f7c4addd8e2146b4b45e035c693cc558",
      "value": 570
     }
    },
    "419a7943ed37457c970370a10a84d916": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_113a61d6c9d24dd5bb1ad7c68b60d340",
       "IPY_MODEL_f5bc40fe5dd8412cab460d1feac02397",
       "IPY_MODEL_52b8ccf4212348f2a3cd7b4f049b5d6e"
      ],
      "layout": "IPY_MODEL_9831527b26bd4cd488155a98aa4ec661"
     }
    },
    "46929edf6ad54411a531ee7c60973bc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a2829465b004a1496976ce2cdf30c26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52b8ccf4212348f2a3cd7b4f049b5d6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_922e5c71c5914e8eafefbd23c5c0dfe1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2dcf4b880d984be8aa26095f45efb796",
      "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡26.1MB/s]"
     }
    },
    "59d0d5d8e2e24b32a51719a23b450c79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a88d0525d04e418498a95932e6cb9bc7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6609b1ff7b054fadbb1a2f7039cab62a",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "61772e9e02874be48d30d6e2706c203a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a995c7a035d441ea370cebe72eaf8f0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e53607d484084e1ca67d5b2197900e75",
      "value": "â€‡48.0/48.0â€‡[00:00&lt;00:00,â€‡4.23kB/s]"
     }
    },
    "6609b1ff7b054fadbb1a2f7039cab62a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "687c1412605b456e81b657a66de40d68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b68842c581f4027a61756cd1712ccc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_961c3571d38e4c13a76d6246470f9497",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4a2829465b004a1496976ce2cdf30c26",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "7072ae437f054c679f1f638ddc8a5fcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77b2a19e25a24d90ad73a865505d68a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59d0d5d8e2e24b32a51719a23b450c79",
       "IPY_MODEL_8352f29cbe2a42069fd1c2491e54355c",
       "IPY_MODEL_837cfc32f9a34ada8c810fe3ba9b889b"
      ],
      "layout": "IPY_MODEL_687c1412605b456e81b657a66de40d68"
     }
    },
    "833cf2599d574c79815f1abd963d2b4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_867c79cb14b24ad4a9001f480c03ceae",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a519dd3bafa941ea8c096dd957361baf",
      "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡5.15MB/s]"
     }
    },
    "8352f29cbe2a42069fd1c2491e54355c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_866d39cfef2243cf8921df0b6c056ed6",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84c0c32bf99045fd9a23bfcb55189242",
      "value": 440449768
     }
    },
    "837cfc32f9a34ada8c810fe3ba9b889b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc246ef0646b4c9eaa44b627eb35557c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_dc22f864fc8f4ec3a63d573ee2d785c1",
      "value": "â€‡440M/440Mâ€‡[00:02&lt;00:00,â€‡200MB/s]"
     }
    },
    "84c0c32bf99045fd9a23bfcb55189242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "866d39cfef2243cf8921df0b6c056ed6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "867c79cb14b24ad4a9001f480c03ceae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "922e5c71c5914e8eafefbd23c5c0dfe1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "961c3571d38e4c13a76d6246470f9497": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9831527b26bd4cd488155a98aa4ec661": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b39f39e51cc43a4a85c09f02bef2baa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bc755cbdd6745d3a872a07229f913fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc5116f44b6249d2baa9c72fa1850f0c",
       "IPY_MODEL_13c55af7d4aa41749834e95f24c847d6",
       "IPY_MODEL_833cf2599d574c79815f1abd963d2b4a"
      ],
      "layout": "IPY_MODEL_9b39f39e51cc43a4a85c09f02bef2baa"
     }
    },
    "a0ff159a3dc548c5881db5b772f0c6e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a519dd3bafa941ea8c096dd957361baf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a88d0525d04e418498a95932e6cb9bc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9fe243d8cfe48a7900c9b8784f3f951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed57552d689b405b9dc63eb2ebf89628",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bfe550841e0340efa726623d13d56d42",
      "value": "â€‡570/570â€‡[00:00&lt;00:00,â€‡46.1kB/s]"
     }
    },
    "bfe550841e0340efa726623d13d56d42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c05bcb16a4e74722a18f68407b9f9e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3528559911c6447e8145c4f5da80f15a",
       "IPY_MODEL_3ad62049d0514655912c801a3a6c33af",
       "IPY_MODEL_a9fe243d8cfe48a7900c9b8784f3f951"
      ],
      "layout": "IPY_MODEL_e67f94e0b1fe4cdf9be788540ba5b921"
     }
    },
    "c72903775d144d0e8531bc5206346fe5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0ff159a3dc548c5881db5b772f0c6e2",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_258c4abcb7614310b46626b3ad75f26c",
      "value": 48
     }
    },
    "cc5116f44b6249d2baa9c72fa1850f0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1fb34004a1304c3f99053b68e0aa978e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fdfac33240d04a9b8ae1f279ef3f9e1e",
      "value": "vocab.txt:â€‡100%"
     }
    },
    "dbd76c78abf64bd7be9161ed777972bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc22f864fc8f4ec3a63d573ee2d785c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc246ef0646b4c9eaa44b627eb35557c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e53607d484084e1ca67d5b2197900e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e67f94e0b1fe4cdf9be788540ba5b921": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed57552d689b405b9dc63eb2ebf89628": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed87a50374dc4cf3906ba1bdffcab1cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5bc40fe5dd8412cab460d1feac02397": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbd76c78abf64bd7be9161ed777972bb",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46929edf6ad54411a531ee7c60973bc0",
      "value": 466062
     }
    },
    "f7c4addd8e2146b4b45e035c693cc558": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fdfac33240d04a9b8ae1f279ef3f9e1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
